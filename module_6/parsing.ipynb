{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://auto.ru/cars/used/sale/skoda/octavia/1100575026-c780dc09/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.car_url[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Парсинг ссылок (Москва)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SKODA',\n",
       " 'AUDI',\n",
       " 'HONDA',\n",
       " 'VOLVO',\n",
       " 'BMW',\n",
       " 'NISSAN',\n",
       " 'INFINITI',\n",
       " 'MERCEDES',\n",
       " 'TOYOTA',\n",
       " 'LEXUS',\n",
       " 'VOLKSWAGEN',\n",
       " 'MITSUBISHI']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_list = list(test.brand.unique())\n",
    "brand_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://auto.ru/moskva/cars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_msk = []\n",
    "for brand in brand_list:\n",
    "    print(brand)\n",
    "    for i in tqdm(range(100)):\n",
    "        new_url = url + brand + '/used/?page=' + str(i+1)\n",
    "        res = requests.get(new_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        blocks = soup.find_all('div', class_='ListingItem-module__container')\n",
    "        h3 = list(map(lambda x: x.find('h3', 'ListingItemTitle-module__container'), blocks))\n",
    "        links_msk += list(map(lambda x: x.find('a', 'ListingItemTitle-module__link')['href'], h3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_msk = set(links_msk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Парсинг ссылок (СПб)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SKODA',\n",
       " 'AUDI',\n",
       " 'HONDA',\n",
       " 'VOLVO',\n",
       " 'BMW',\n",
       " 'NISSAN',\n",
       " 'INFINITI',\n",
       " 'MERCEDES',\n",
       " 'TOYOTA',\n",
       " 'LEXUS',\n",
       " 'VOLKSWAGEN',\n",
       " 'MITSUBISHI']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_list = list(test.brand.unique())\n",
    "brand_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://auto.ru/sankt-peterburg/cars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_spb = []\n",
    "for brand in tqdm(brand_list):\n",
    "    for i in range(100):\n",
    "        new_url = url + brand + '/used/?page=' + str(i+1)\n",
    "        res = requests.get(new_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        time.sleep(0.3)\n",
    "        blocks = soup.find_all('div', class_='ListingItem-module__container')\n",
    "        h3 = list(map(lambda x: x.find('h3', 'ListingItemTitle-module__container'), blocks))\n",
    "        links_spb += list(map(lambda x: x.find('a', 'ListingItemTitle-module__link')['href'], h3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_spb = set(links_spb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Парсинг объявлений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = links_spb + links_msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in tqdm(links):\n",
    "    try:\n",
    "        res = requests.get(url)\n",
    "        res.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        \n",
    "        script1 = soup.find('script', type='application/ld+json').contents[0]\n",
    "        script1_json = json.loads(script1)\n",
    "        script2 = soup.find('script', id='initial-state').contents[0]\n",
    "        script2_json = json.loads(script2)\n",
    "        ul = soup.find('ul', class_='CardInfo')\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    train = {}\n",
    "\n",
    "    try:\n",
    "        train['bodyType'] = script1_json['bodyType']   \n",
    "    except:\n",
    "        np.nan        \n",
    "    try:\n",
    "        train['brand'] = script1_json['brand']\n",
    "    except:\n",
    "        np.nan   \n",
    "    try:\n",
    "        train['car_url'] = script1_json['offers']['url']\n",
    "    except:\n",
    "        np.nan   \n",
    "    try:\n",
    "        train['color'] = script1_json['color']\n",
    "    except:\n",
    "        np.nan   \n",
    "    try:\n",
    "        train['complectation_dict'] = np.nan\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['description'] = script1_json['description']\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['engineDisplacement'] = script1_json['vehicleEngine']['engineDisplacement']\n",
    "    except:\n",
    "        np.nan   \n",
    "    try:\n",
    "        train['enginePower'] = script1_json['vehicleEngine']['enginePower']\n",
    "    except:\n",
    "        np.nan   \n",
    "    try:\n",
    "        train['equipment_dict'] = str(script2_json['card']['vehicle_info']['equipment'])\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['fuelType'] = script1_json['vehicleEngine']['fuelType']\n",
    "    except:\n",
    "        np.nan   \n",
    "    try:\n",
    "        train['image'] = script1_json['image']\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['mileage'] = script2_json['card']['state']['mileage']\n",
    "    except:\n",
    "        np.nan   \n",
    "    try:\n",
    "        train['modelDate'] = script1_json['modelDate']\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['model_info'] = str(script2_json['card']['vehicle_info']['model_info'])\n",
    "    except:\n",
    "        np.nan   \n",
    "    try:\n",
    "        train['model_name'] = script2_json['card']['vehicle_info']['model_info']['code']\n",
    "    except:\n",
    "        np.nan\n",
    "        \n",
    "    try:\n",
    "        train['name'] = script2_json['card']['vehicle_info']['tech_param']['human_name']\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['numberOfDoors'] = script1_json['numberOfDoors']\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['parsing_unixtime'] = int(time.time())\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['priceCurrency'] = script1_json['offers']['priceCurrency']\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['productionDate'] = script1_json['productionDate']\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['sell_id'] = script2_json['card']['id']\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['super_gen'] = str(script2_json['card']['vehicle_info']['tech_param'])\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['vehicleConfiguration'] = script1_json['vehicleConfiguration']\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['vehicleTransmission'] = script1_json['vehicleTransmission']\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['vendor'] = np.nan\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['Владельцы'] = ul.find_all('li', class_='CardInfoRow_ownersCount')[0].find_all('span')[1].text\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['Владение'] = ul.find_all('li', class_='CardInfoRow_owningTime')[0].find_all('span')[1].text\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['ПТС'] = ul.find_all('li', class_='CardInfoRow_pts')[0].find_all('span')[1].text\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['Привод'] = ul.find_all('li', class_='CardInfoRow_drive')[0].find_all('span')[1].text\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['Руль'] = ul.find_all('li', class_='CardInfoRow_wheel')[0].find_all('span')[1].text\n",
    "    except:\n",
    "        np.nan    \n",
    "    try:\n",
    "        train['Состояние'] = ul.find_all('li', class_='CardInfoRow_state')[0].find_all('span')[1].text\n",
    "    except:\n",
    "        np.nan\n",
    "    try:\n",
    "        train['Таможня'] = ul.find_all('li', class_='CardInfoRow_customs')[0].find_all('span')[1].text\n",
    "    except:\n",
    "        np.nan\n",
    "    try:\n",
    "        train['price'] = script1_json['offers']['price']\n",
    "    except:\n",
    "        np.nan \n",
    "        \n",
    "    df_train = df_train.append([train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('train.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
